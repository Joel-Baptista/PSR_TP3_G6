#!/usr/bin/env python3
import argparse
import math
import time
import cv2
from cv_bridge import CvBridge
import numpy as np
import colorama
from operator import itemgetter
import rospy
import copy
from sensor_msgs.msg import Image, LaserScan, CameraInfo
from std_msgs.msg import Header, ColorRGBA
import tf2_geometry_msgs
import tf2_ros
from visualization_msgs.msg import Marker, MarkerArray
from geometry_msgs.msg import Twist, PoseStamped, Point, Pose, Vector3, Quaternion
from p_g06_sensors.msg import PlayerLocation

class Camera:
    def __init__(self):
        # <==============================================================>
        # <================ VARIABLE INITIATION =========================>
        # <==============================================================>

        # <----------------COMPUTER VISION VARIABLES--------------------->

        self.window_name = 'CV_image'

        self.kernel_lineY = np.ones((10, 1), np.uint8) # These are matrixs used for morfologic transformation
        self.kernel_lineX = np.ones((1, 10), np.uint8) # applied on the binarized images
        self.kernel_square = np.ones((3, 3), np.uint8)

        self.img = np.zeros((100, 200))

        self.camera_info_exist = False

        self.spotedPlayers = []

        self.Objects = []

        self.team = ["Blue", "Green", "Red"]

        self.img_gui = np.zeros((100, 200))

        # <-------------------LIDAR 2D VARIABLES------------------------->

        self.LidarPoints = []
        self.Lidar_object_centroid = []
        self.Lidar_object_points = []

        # <-------------------COMMUNICATION VARIABLES-------------------->

        self.name = rospy.get_name()

        self.name = self.name.strip("/")
        idx = self.name.find("_", 0, len(self.name))

        self.name = self.name[0:idx]
        print("My player name is " + self.name)

        topic_image = "/" + self.name + '/camera/rgb/image_raw'
        topic_laser = "/" + self.name + '/scan'
        topic_camera = "/" + self.name + '/camera/rgb/camera_info'
        topic_marker = "/" + self.name + '/markers'
        topic_location = "/" + self.name + '/player_location'

        print("I'm subscribing to " + topic_image)
        print("I'm subscribing to " + topic_laser)
        print("I'm subscribing to " + topic_camera)
        print("I'm publishing to " + topic_marker)
        print("I'm publishing to " + topic_location)

        # <==============================================================>
        # <================ COMMUNICATION INITIATION ====================>
        # <==============================================================>

        # <-------------------SUBSCRIBERS INITIATION--------------------->
        # Subscribes to needed topics to retrieve necessary information

        self.subscriber_img = rospy.Subscriber(topic_image, Image, self.getImageCallback) # Gets image from camera
        self.subscriber_laser = rospy.Subscriber(topic_laser, LaserScan, self.getLaserCallback) # Gets points from laser
        self.subscriber_camera = rospy.Subscriber(topic_camera, CameraInfo, self.getCameraInfoCallback) # Gets parameters from camera

        # <-------------------PUBLISHERS INITIATION--------------------->
        # Publishes information to topics
        self.publisher_location = rospy.Publisher(topic_location, PlayerLocation, queue_size=10)  # Publishes markers to rviz to ensure that the data is correct
        self.publisher_markers = rospy.Publisher(topic_marker, MarkerArray, queue_size=10) # Publishes markers to rviz to ensure that the data is correct
        # self.timer = rospy.Timer(rospy.Duration(0.1), self.sendMarkersCallback)
        # self.timer_object_detection = rospy.Timer(rospy.Duration(0.1), self.object_detection())
        # <-------------------TF_LISTENER INITIATION--------------------->
        # Initiates frames' transform listener in order easily transform data from one frame from another frame

        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer)

    # <==========================================================================================================>
    # <---------------------------------------------------------------------------------------------------------->
    # <------------------------------------COMMUNICATION FUNCTIONS----------------------------------------------->
    # <---------------------------------------------------------------------------------------------------------->
    # <==========================================================================================================>

    def sendPlayerLocation(self, Objects):
        p_loc = PlayerLocation()
        idx = []
        teams = []
        locations = []
        Xpixels = []
        Ypixels = []

        for i, object in enumerate(Objects):
            idx.append(i)
            teams.append(object["team"])

            centroid = np.mean(object["pixels"], axis=0)

            Xpixels.append(int(centroid[0]))
            Ypixels.append(int(centroid[1]))

            poseStamped = PoseStamped()

            poseStamped.header = Header(stamp=rospy.Time.now(), frame_id=self.name + "/camera_rgb_frame")

            average_point = np.mean(object["points"], axis=0)
            point = Point()
            point.x = average_point[0]
            point.y = average_point[1]
            point.z = average_point[2]

            quaternion = Quaternion(x=0, y=0, z=0, w=1)

            poseStamped.pose = Pose(position=point, orientation=quaternion)

            locations.append(poseStamped)

        p_loc.idx = idx
        p_loc.teams = teams
        p_loc.locations = locations
        p_loc.Xpixel = Xpixels
        p_loc.Ypixel = Ypixels

        self.publisher_location.publish(p_loc)


    def sendMarkersCallback(self, Objects):
        markers_array = MarkerArray()

        for i, object in enumerate(Objects):

            marker = Marker()
            marker.ns = "cylinder" + str(i)
            marker.header = Header(stamp=rospy.Time.now(), frame_id=self.name + "/camera_rgb_frame")
            marker.type = Marker.CUBE

            scale = Vector3(x=0.3, y=0.3, z=0.29)
            marker.scale = scale

            average_point = np.mean(object["points"], axis=0)
            point = Point()
            point.x = average_point[0]
            point.y = average_point[1]
            point.z = average_point[2]

            quaternion = Quaternion(x=0, y=0, z=0, w=1)

            if object["team"] == "Red":
                color = ColorRGBA(r=1, g=0, b=0, a=0.3)
            elif object["team"] == "Blue":
                color = ColorRGBA(r=0, g=0, b=1, a=0.3)
            elif object["team"] == "Green":
                color = ColorRGBA(r=0, g=1, b=0, a=0.3)
            else:
                color = ColorRGBA(r=1, g=0, b=1, a=0.3)

            marker.color = color

            marker.pose = Pose(position=point, orientation=quaternion)

            markers_array.markers.append(marker)

        self.publisher_markers.publish(markers_array)

    def getImageCallback(self, img): # Gets image from robot's camera and coverts the image to be used by OpenCV
        bridge = CvBridge()
        cv_img = bridge.imgmsg_to_cv2(img, desired_encoding='passthrough')
        cv_bgr = cv2.cvtColor(cv_img, cv2.COLOR_RGB2BGR)
        cv_hsv= cv2.cvtColor(cv_img, cv2.COLOR_RGB2HSV)

        cv2.imshow(self.window_name, cv_bgr)
        self.img = cv_hsv
        self.img_gui = copy.deepcopy(cv_bgr)
        key = cv2.waitKey(1)


        if len(self.LidarPoints) > 0:
            self.object_detection()


    def getCameraInfoCallback(self, msg): # Gets the camera parameters from the robot's camera
        try:
            self.D = msg.D
            self.K = msg.K
            self.P = msg.P
            self.height = msg.height
            self.width = msg.width

            self.camera_info_exist = True

        except(tf2_ros.LookupException, tf2_ros.ConnectivityException, tf2_ros.ExtrapolationException):
            self.camera_info_exist = False
            rospy.logerr("Could not get camera parameters.")


    def getLaserCallback(self, laser): # Gets Lidar 2D points from the robot's sensor
        self.LidarPoints = []
        lidar_array = np.empty((0, 3), float)

        for i, range in enumerate(laser.ranges):
            theta = laser.angle_min + laser.angle_increment * i
            if ((math.pi / 5 >= theta >= 0) or ((9 * math.pi) / 5 <= theta <= 2 * math.pi)) and not math.isinf(range):
                # The if statement limits the angle of the Lidar 2D point that will be analised (angles can be changed if needed)

                x = range * math.cos(theta)
                y = range * math.sin(theta)
                z = 0

                lidar_array = np.append(lidar_array, np.array([[x, y, z]]), axis=0)

        lidar_array_sorted = sorted(lidar_array, key=itemgetter(1))

        for lidar_point in lidar_array_sorted:

            poseStamped = PoseStamped()
            point = Point()

            poseStamped.header.stamp = rospy.Time.now()
            poseStamped.header.frame_id = self.name + "/base_scan"

            point.x = lidar_point[0]
            point.y = lidar_point[1]
            point.z = lidar_point[2]

            poseStamped.pose.position = point

            self.LidarPoints.append(poseStamped)

        self.LidarPoints_in_camera_frame = self.lidar_to_camera_frame(self.LidarPoints)

    # <==========================================================================================================>
    # <---------------------------------------------------------------------------------------------------------->
    # <----------------------------------IMAGE PROCESSING FUNCTIONS---------------------------------------------->
    # <---------------------------------------------------------------------------------------------------------->
    # <==========================================================================================================>

    def get_binary_mask(self):

        # mask_R = cv2.inRange(self.img, (0, 0, 0), (0, 0, 6))
        # mask_G = cv2.inRange(self.img, (0, 243, 0), (31, 4, 0))
        # mask_B = cv2.inRange(self.img, (116, 0, 0), (146, 4, 6))

        mask_R1 = cv2.inRange(self.img, (0, 150, 100), (21, 256, 256))
        mask_R2 = cv2.inRange(self.img, (234, 150, 100), (256, 256, 256))
        mask_R = cv2.bitwise_or(mask_R1, mask_R2)
        mask_G = cv2.inRange(self.img, (42, 100, 100), (113, 256, 256))
        mask_B = cv2.inRange(self.img, (100, 100, 100), (200, 256, 256))

        # mask = cv2.inRange(self.img, (0, 150, 100), (21, 256, 256))
        # cv2.imshow("mask", mask)
        # masks = [mask, mask, mask]
        masks = [mask_B, mask_G, mask_R]
        final_masks = []

        for mask in masks:

            mask_dilation = cv2.dilate(mask, self.kernel_lineY, iterations=2)  # Dilates the mask in the Y-direction, because the robots are built by layers
            mask_closing = cv2.morphologyEx(mask_dilation, cv2.MORPH_CLOSE, self.kernel_square)  # Closes the holes in the mask
            mask_dilation = cv2.dilate(mask_closing, self.kernel_lineX, iterations=2)  # Dilates the mask in the X-direction to mantain the robot's shape
            mask_erode = cv2.erode(mask_dilation, self.kernel_square, iterations=7)  # Because of all the previous dilations, an erode function is needed

            final_masks.append(mask_erode)

        all_masks = cv2.bitwise_or(final_masks[0], final_masks[1])
        all_masks = cv2.bitwise_or(final_masks[2], all_masks)

        cv2.add(self.img_gui, (-10, 60, -10, 0), dst=self.img_gui, mask=all_masks)

        return final_masks

    def points_to_pixels(self, points):

        array_lidarPoints = np.zeros((len(points), 3))

        # As the points are already on the camera's frame, there is no rotation and translation needed
        R = np.array([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])
        T = np.array([0., 0., 0.])

        idx = 0
        for lidarPoint in points:
            # As the Lidar points come in meters, and the cameras parameters are in milimeters, it was necessary to scale the values
            # The axis x, y and z also had to be switched because OpenCV and the frames of Lidar were not compatible

            x = -lidarPoint[1]/1000
            y = lidarPoint[2]/1000
            z = lidarPoint[0]/1000

            vector_lidarPoint = np.array([x, y, z])

            array_lidarPoints[idx] = vector_lidarPoint
            idx += 1

        if self.camera_info_exist and len(array_lidarPoints) > 0:
            K = np.asarray(self.K).reshape((3, 3))
            array_lidarPixels = cv2.projectPoints(array_lidarPoints, R, T, K, self.D)
        else:
            array_lidarPixels = np.array([])

        dim = array_lidarPixels[0].shape
        return np.around(array_lidarPixels[0]).reshape((dim[0], 2))

    # <==========================================================================================================>
    # <---------------------------------------------------------------------------------------------------------->
    # <------------------------------------FRAME CHANGING FUNCTIONS---------------------------------------------->
    # <---------------------------------------------------------------------------------------------------------->
    # <==========================================================================================================>

    def lidar_to_camera_frame(self, LidarPoints):
        LaserPoints_in_camera = []
        for laser_point in LidarPoints:
            LaserPoint_in_camera = self.tf_buffer.transform(laser_point, self.name + "/camera_rgb_frame",
                                                            rospy.Duration(1))
            LaserPoints_in_camera.append(LaserPoint_in_camera)

        return LaserPoints_in_camera

    # <==========================================================================================================>
    # <---------------------------------------------------------------------------------------------------------->
    # <------------------------------------OBJECT DETECTION FUNCTIONS-------------------------------------------->
    # <---------------------------------------------------------------------------------------------------------->
    # <==========================================================================================================>

    def object_detection(self):
        # IMPORTANT: This function calls markers and player_location publisher
        # IMPORTANT: For now, this function is only called if there are LIDAR point in front of the robot and
        # an image is received from the camera

        objects_lidar_points = self.lidar_object_detection()

        masks = self.get_binary_mask()
        self.Objects = []

        for k, mask in enumerate(masks):

            contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)  # finds objects

            for i, contour in enumerate(contours):

                player_mask = np.zeros(self.img.shape)
                player_mask = cv2.fillPoly(player_mask, pts=[contour], color=(255, 255, 255))

                p_mask, _, _ = cv2.split(player_mask)

                object = {}

                for j, lidar_points in enumerate(objects_lidar_points):

                    objects_lidar_pixels = self.points_to_pixels(lidar_points)
                    mask_object = np.zeros(masks[0].shape).astype(np.uint8)

                    for lidar_pixel in objects_lidar_pixels:
                        x = int(lidar_pixel[0])
                        y = int(lidar_pixel[1])

                        cv2.circle(self.img_gui, (x, y), 2, (255, 0, 255), -1)

                        if x <= self.width - 1 and y <= self.height - 1:
                            mask_object[y][x] = 255

                    cond = cv2.bitwise_and(p_mask.astype(np.uint8), mask_object)

                    if np.sum(cond > 0) == np.sum(mask_object > 0):
                        object = {"id": i, "pixels": objects_lidar_pixels, "points": lidar_points, "team": self.team[k]}
                        self.Objects.append(object)
                        break

                if len(object) == 0:
                    M = cv2.moments(contour)  # Finds the object's moments
                    cX = int(M['m10'] / M['m00'])  # With the moments, calculates the object's centroid
                    cY = int(M['m01'] / M['m00'])

                    pixels = np.array([[cX, cY], [cX, cY]])
                    lidar = np.array([[0, 0, 0], [0, 0, 0]])

                    object = {"id": i, "pixels": pixels, "points": lidar, "team": self.team[k]}
                    self.Objects.append(object)

        cv2.imshow("window", self.img_gui)
        self.sendMarkersCallback(self.Objects)
        self.sendPlayerLocation(self.Objects)

    def lidar_object_detection(self):
        x_prev = 1000
        y_prev = 1000

        tresh = 0.2

        points_list = []
        array_points = np.empty((0, 3), float)

        for i, lidar_point in enumerate(self.LidarPoints_in_camera_frame):
            x = lidar_point.pose.position.x
            y = lidar_point.pose.position.y
            z = lidar_point.pose.position.z

            dist = math.sqrt((x - x_prev) ** 2 + (y - y_prev) ** 2)
            if dist > tresh:
                if i > 0:
                    points_list.append(array_points)

                array_points = np.empty((0, 3), float)

            array_points = np.append(array_points, np.array([[x, y, z]]), axis=0)
            x_prev = x
            y_prev = y

        points_list.append(array_points)

        return points_list

def main():
    # ---------------------------------------------------
    # INITIALIZATION
    # ---------------------------------------------------

    rospy.init_node('Camera', anonymous=False)

    camera = Camera()

    rospy.spin()


if __name__ == '__main__':
    main()
